{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cortical Surface Analysis with Spherical Harmonics\n",
    "\n",
    "This notebook provides a complete analysis of cortical surfaces using spherical harmonics.\n",
    "\n",
    "## Contents:\n",
    "1. **Setup & Data Loading**\n",
    "2. **Reconstruction Quality Analysis** \n",
    "3. **Brain Reconstruction**\n",
    "4. **Coefficient Properties Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import scipy.io as sio\n",
    "\n",
    "# Add path for imports\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.mathutils import compute_vertex_normals, build_template_adjacency_two_hemis, compute_mean_curvature, hausdorff_distance\n",
    "from utils.cortical import spherical_harmonics as SH\n",
    "from utils.cortical import surface_preprocess as sp\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - UPDATE THESE PATHS\n",
    "# Ensure these paths are correct for your environment\n",
    "DATA_PATH = r\"C:\\Users\\wbou2\\Documents\\meg_to_surface_ml\\src\\cortical_transformation\\data\"\n",
    "SUBJECTS_DIR = r\"C:\\Users\\wbou2\\Documents\\meg_to_surface_ml\\data\\Anatomy_data_CAM_CAN\"\n",
    "\n",
    "# Load templates and harmonics\n",
    "print(\"Loading templates and harmonics...\")\n",
    "template_lh = np.load(os.path.join(DATA_PATH, \"lh_sphere_projection.npz\"))\n",
    "template_rh = np.load(os.path.join(DATA_PATH, \"rh_sphere_projection.npz\"))\n",
    "Y_lh_full = np.load(os.path.join(DATA_PATH, \"Y_lh.npz\"))['Y']\n",
    "Y_rh_full = np.load(os.path.join(DATA_PATH, \"Y_rh.npz\"))['Y']\n",
    "\n",
    "# Get subject list\n",
    "subjects = [f for f in os.listdir(SUBJECTS_DIR) \n",
    "           if os.path.isdir(os.path.join(SUBJECTS_DIR, f)) and f.startswith(\"sub-\")]\n",
    "\n",
    "print(f\"Found {len(subjects)} subjects\")\n",
    "print(f\"Harmonics shape - LH: {Y_lh_full.shape}, RH: {Y_rh_full.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reconstruction Quality Analysis\n",
    "\n",
    "Analyze how reconstruction quality changes with different harmonic orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reconstruction_error(subject_path, hemi, Y_full, l, vertex_to_faces):\n",
    "    \"\"\"Compute reconstruction error for one subject/hemisphere\"\"\"\n",
    "    # Load data\n",
    "    coeffs_path = os.path.join(subject_path, f\"coeffs_{hemi}.pkl\")\n",
    "    resampled_path = os.path.join(subject_path, f\"{hemi}_resampled.npz\")\n",
    "    \n",
    "    if not (os.path.exists(coeffs_path) and os.path.exists(resampled_path)):\n",
    "        return None\n",
    "        \n",
    "    with open(coeffs_path, 'rb') as f:\n",
    "        coeffs = pickle.load(f)\n",
    "    resampled_data = np.load(resampled_path)\n",
    "    \n",
    "    # Truncate harmonics and coefficients\n",
    "    Y_trunc = Y_full[:, :(l+1)**2]\n",
    "    org_coeffs = {i: coeffs['organized_coeffs'][i] for i in range(l+1) \n",
    "                 if i in coeffs['organized_coeffs']}\n",
    "    \n",
    "    # Reconstruct surface\n",
    "    recon_surface = SH.generate_surface(Y_trunc, l, 0, org_coeffs)\n",
    "    \n",
    "    # Calculate normalized Hausdorff distance\n",
    "    hausdorff = hausdorff_distance(resampled_data['coords'], recon_surface)\n",
    "    char_size = np.max(np.ptp(resampled_data['coords'], axis=0))\n",
    "    \n",
    "    return hausdorff / char_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis parameters\n",
    "MAX_L = 50\n",
    "STEP = 5\n",
    "l_values = list(range(5, MAX_L+1, STEP))\n",
    "\n",
    "print(f\"Analyzing reconstruction quality for l values: {l_values}\")\n",
    "\n",
    "# Build adjacency once (for efficiency)\n",
    "print(\"Building vertex adjacency...\")\n",
    "vertex_to_faces = build_template_adjacency_two_hemis(\n",
    "    template_lh['sphere_tris'], \n",
    "    template_rh['sphere_tris']\n",
    ")\n",
    "\n",
    "# Store results\n",
    "quality_metrics = {'l_values': l_values, 'lh_errors': [], 'rh_errors': []}\n",
    "\n",
    "# Process each l value\n",
    "for l in tqdm(l_values, desc=\"Processing l values\"):\n",
    "    lh_errors, rh_errors = [], []\n",
    "    \n",
    "    for subject in subjects:\n",
    "        subject_path = os.path.join(SUBJECTS_DIR, subject)\n",
    "        \n",
    "        # Process both hemispheres\n",
    "        lh_error = compute_reconstruction_error(subject_path, 'lh', Y_lh_full, l, vertex_to_faces)\n",
    "        rh_error = compute_reconstruction_error(subject_path, 'rh', Y_rh_full, l, vertex_to_faces)\n",
    "        \n",
    "        if lh_error is not None:\n",
    "            lh_errors.append(lh_error)\n",
    "        if rh_error is not None:\n",
    "            rh_errors.append(rh_error)\n",
    "    \n",
    "    # Store mean errors\n",
    "    quality_metrics['lh_errors'].append(np.mean(lh_errors) if lh_errors else np.nan)\n",
    "    quality_metrics['rh_errors'].append(np.mean(rh_errors) if rh_errors else np.nan)\n",
    "\n",
    "print(\"Quality analysis completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reconstruction quality\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(quality_metrics['l_values'], quality_metrics['lh_errors'], \n",
    "         'o-', label='Left Hemisphere', color='blue', linewidth=2)\n",
    "plt.plot(quality_metrics['l_values'], quality_metrics['rh_errors'], \n",
    "         'o-', label='Right Hemisphere', color='red', linewidth=2)\n",
    "\n",
    "plt.xlabel('Harmonic Order (l)', fontsize=12)\n",
    "plt.ylabel('Normalized Hausdorff Distance', fontsize=12)\n",
    "plt.title('Reconstruction Quality vs Harmonic Order', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=11)\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Brain Reconstruction\n",
    "\n",
    "Reconstruct complete 3D brain models and save them as MATLAB files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_hemisphere(hemi, l, coeffs, center, Y_full):\n",
    "    \"\"\"Reconstruct one hemisphere\"\"\"\n",
    "    Y_trunc = Y_full[:, :(l+1)**2]\n",
    "    org_coeffs = {i: coeffs['organized_coeffs'][i] for i in range(l+1)}\n",
    "    coords = SH.generate_surface(Y_trunc, l, 0, org_coeffs)\n",
    "    return coords + center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction parameters\n",
    "RECONSTRUCTION_L = 30  # Use the optimal l or adjust as needed\n",
    "\n",
    "print(f\"Reconstructing all brains with l={RECONSTRUCTION_L}...\")\n",
    "\n",
    "# Get triangulation from first subject\n",
    "first_subject_path = os.path.join(SUBJECTS_DIR, subjects[0])\n",
    "tris = np.load(os.path.join(first_subject_path, \"lh_resampled.npz\"))['tris']\n",
    "\n",
    "# Reconstruct each subject\n",
    "reconstruction_results = []\n",
    "\n",
    "for subject in tqdm(subjects, desc=\"Reconstructing brains\"):\n",
    "    subject_path = os.path.join(SUBJECTS_DIR, subject)\n",
    "    \n",
    "    try:\n",
    "        # Load centers and coefficients\n",
    "        lh_data = np.load(os.path.join(subject_path, \"lh_resampled.npz\"))\n",
    "        rh_data = np.load(os.path.join(subject_path, \"rh_resampled.npz\"))\n",
    "        \n",
    "        with open(os.path.join(subject_path, \"coeffs_lh.pkl\"), 'rb') as f:\n",
    "            coeffs_lh = pickle.load(f)\n",
    "        with open(os.path.join(subject_path, \"coeffs_rh.pkl\"), 'rb') as f:\n",
    "            coeffs_rh = pickle.load(f)\n",
    "        \n",
    "        # Reconstruct hemispheres\n",
    "        lh_coords = reconstruct_hemisphere('lh', RECONSTRUCTION_L, coeffs_lh, lh_data['center'], Y_lh_full)\n",
    "        rh_coords = reconstruct_hemisphere('rh', RECONSTRUCTION_L, coeffs_rh, rh_data['center'], Y_rh_full)\n",
    "        \n",
    "        # Merge hemispheres\n",
    "        merged_coords, merged_tris = sp.merge_hemis((lh_coords, tris), (rh_coords, tris))\n",
    "        \n",
    "        # Save as .mat file for MATLAB\n",
    "        TessMat = {\n",
    "            'Vertices': merged_coords,\n",
    "            'Faces': merged_tris + 1  # MATLAB uses 1-based indexing\n",
    "        }\n",
    "        mat_path = os.path.join(subject_path, 'brain_reconstructed.mat')\n",
    "        sio.savemat(mat_path, {'TessMat': TessMat})\n",
    "        \n",
    "        reconstruction_results.append({\n",
    "            'subject': subject,\n",
    "            'n_vertices': len(merged_coords),\n",
    "            'n_faces': len(merged_tris),\n",
    "            'success': True\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reconstructing {subject}: {e}\")\n",
    "        reconstruction_results.append({\n",
    "            'subject': subject,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "# Summary\n",
    "successful = sum(1 for r in reconstruction_results if r['success'])\n",
    "print(f\"\\nReconstruction completed: {successful}/{len(subjects)} subjects successful\")\n",
    "\n",
    "if successful > 0:\n",
    "    example_result = next(r for r in reconstruction_results if r['success'])\n",
    "    print(f\"Example: {example_result['n_vertices']} vertices, {example_result['n_faces']} faces per brain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Coefficient Properties Analysis\n",
    "\n",
    "Analyze the properties of spherical harmonic coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all coefficients\n",
    "print(\"Loading all coefficients...\")\n",
    "all_coeffs = {'lh': [], 'rh': []}\n",
    "\n",
    "for subject in tqdm(subjects, desc=\"Loading coefficients\"):\n",
    "    subject_path = os.path.join(SUBJECTS_DIR, subject)\n",
    "    \n",
    "    try:\n",
    "        for hemi in ['lh', 'rh']:\n",
    "            with open(os.path.join(subject_path, f\"coeffs_{hemi}.pkl\"), 'rb') as f:\n",
    "                coeffs = pickle.load(f)\n",
    "            all_coeffs[hemi].append(coeffs['organized_coeffs'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading coefficients for {subject}: {e}\")\n",
    "\n",
    "print(f\"Loaded coefficients for {len(all_coeffs['lh'])} subjects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze spectral power decay\n",
    "def compute_spectral_power(coeffs_list, max_l=50):\n",
    "    \"\"\"Compute spectral power for each harmonic order\"\"\"\n",
    "    powers = []\n",
    "    \n",
    "    for subject_coeffs in coeffs_list:\n",
    "        subject_powers = []\n",
    "        for l in range(1, min(max_l+1, len(subject_coeffs))):\n",
    "            if l in subject_coeffs:\n",
    "                # Calculate power for this order (sum over all coordinates)\n",
    "                power = np.sum(np.abs(subject_coeffs[l])**2)\n",
    "                subject_powers.append(power)\n",
    "        powers.append(subject_powers)\n",
    "    \n",
    "    return np.array(powers)\n",
    "\n",
    "# Compute powers\n",
    "lh_powers = compute_spectral_power(all_coeffs['lh'])\n",
    "rh_powers = compute_spectral_power(all_coeffs['rh'])\n",
    "\n",
    "# Plot spectral power decay\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "l_range = range(1, lh_powers.shape[1]+1)\n",
    "lh_mean = np.mean(lh_powers, axis=0)\n",
    "rh_mean = np.mean(rh_powers, axis=0)\n",
    "\n",
    "plt.semilogy(l_range, lh_mean, 'o-', color='blue', label='Left Hemisphere', linewidth=2)\n",
    "plt.semilogy(l_range, rh_mean, 'o-', color='red', label='Right Hemisphere', linewidth=2)\n",
    "\n",
    "plt.xlabel('Harmonic Order (l)', fontsize=12)\n",
    "plt.ylabel('Spectral Power (log scale)', fontsize=12)\n",
    "plt.title('Spectral Power Decay Across Harmonic Orders', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print power decay rate\n",
    "decay_rate_lh = np.polyfit(np.log(l_range[10:30]), np.log(lh_mean[10:30]), 1)[0]\n",
    "decay_rate_rh = np.polyfit(np.log(l_range[10:30]), np.log(rh_mean[10:30]), 1)[0]\n",
    "print(f\"Power decay rates (l=10-30): LH={decay_rate_lh:.2f}, RH={decay_rate_rh:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze coefficient distributions for specific orders\n",
    "analysis_orders = [5, 15, 30]\n",
    "\n",
    "fig, axes = plt.subplots(len(analysis_orders), 2, figsize=(12, 4*len(analysis_orders)))\n",
    "if len(analysis_orders) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i, l in enumerate(analysis_orders):\n",
    "    for j, (hemi, color) in enumerate([('lh', 'blue'), ('rh', 'red')]):\n",
    "        # Collect all coefficients for this l and hemisphere\n",
    "        coeffs_flat = []\n",
    "        for subject_coeffs in all_coeffs[hemi]:\n",
    "            if l < len(subject_coeffs) and l in subject_coeffs:\n",
    "                coeffs_flat.extend(np.real(subject_coeffs[l].flatten()))\n",
    "        \n",
    "        # Plot histogram and statistics\n",
    "        axes[i, j].hist(coeffs_flat, bins=50, alpha=0.7, color=color, density=True)\n",
    "        axes[i, j].set_title(f'{hemi.upper()} - Order l={l}\\n(μ={np.mean(coeffs_flat):.3f}, σ={np.std(coeffs_flat):.3f})')\n",
    "        axes[i, j].set_xlabel('Coefficient Value')\n",
    "        axes[i, j].set_ylabel('Density')\n",
    "        axes[i, j].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Overlay normal distribution\n",
    "        x = np.linspace(min(coeffs_flat), max(coeffs_flat), 100)\n",
    "        normal_fit = (1/np.sqrt(2*np.pi*np.var(coeffs_flat))) * np.exp(-0.5*(x-np.mean(coeffs_flat))**2/np.var(coeffs_flat))\n",
    "        axes[i, j].plot(x, normal_fit, 'k--', alpha=0.8, label='Normal fit')\n",
    "        axes[i, j].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provided a complete analysis of cortical surfaces using spherical harmonics:\n",
    "\n",
    "1. **Quality Analysis**: Showed how reconstruction error decreases with higher harmonic orders\n",
    "2. **Brain Reconstruction**: Generated complete 3D brain models from harmonic coefficients\n",
    "3. **Coefficient Properties**: Analyzed spectral power decay and coefficient distributions\n",
    "\n",
    "### Key Findings:\n",
    "- Optimal harmonic order for reconstruction quality\n",
    "- Power law decay of spectral energy\n",
    "- Gaussian-like distribution of coefficients\n",
    "\n",
    "### Output Files:\n",
    "- `brain_reconstructed.mat`: Complete 3D brain models for each subject"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
